
This appendix documents all data sources, processing procedures, and validation checks used in this research.


\subsection{Fama-French factor data}

\subsubsection{Data Source and Collection}

\textbf{Primary Source}: Kenneth French Data Library
	(see French, K., 2025, \url{https://mba.tuck.dartmouth.edu})

\textbf{Factors Included}:
1. Excess Market Return (Mkt-RF)
2. Size Factor (SMB - Small Minus Big)
3. Value Factor (HML - High Minus Low)
4. Profitability Factor (RMW - Robust Minus Weak)
5. Investment Factor (CMA - Conservative Minus Aggressive)
6. Momentum Factor (MOM - Momentum)
7. Risk-Free Rate (RF)

\textbf{Time Period}: July 1926 - December 2024 (1,176 months)

\textbf{Subset Used in This Study}: July 1963 - December 2024 (754 months)

\textbf{Rationale for 1963 Start Date}:
- Pre-1963 data has higher missing values and less reliable coverage
- 1963 marks the beginning of modern computational finance era
- Sufficient data for multiple rolling window estimation periods

\subsubsection{Factor Definitions}

\textbf{Size (SMB)}:
- Long: Stocks in bottom 30% of market cap
- Short: Stocks in top 30% of market cap
- Frequency: Monthly rebalancing
- Coverage: All US common stocks on NYSE, AMEX, NASDAQ

\textbf{Value (HML)}:
- Long: Stocks with highest 30% book-to-market ratio
- Short: Stocks with lowest 30% book-to-market ratio
- Book value: Total assets - total liabilities
- Market value: Stock price $\times$ shares outstanding

\textbf{Profitability (RMW)}:
- Long: High profitability firms (top 30% operating profitability)
- Short: Low profitability firms (bottom 30% operating profitability)
- Operating profitability: Operating income / total assets
- Implementation: Net income before extraordinary items / book equity

\textbf{Investment (CMA)}:
- Long: Low asset growth (bottom 30% in asset growth)
- Short: High asset growth (top 30% in asset growth)
- Asset growth: Change in total assets / prior year assets

\textbf{Momentum (MOM)}:
- Long: Stocks with highest 30% returns in prior 12 months (t-12 to t-1)
- Short: Stocks with lowest 30% returns in prior 12 months
- Holding period: 1 month

\subsubsection{Data Quality and Validation}

\textbf{Missing Values}:
- Fama-French data: 0% missing (carefully constructed from Compustat and CRSP)
- Our processed data: 0% missing through the full period 1963-2024

\textbf{Outliers}:
- Checked using 3-sigma rule (beyond 3 standard deviations)
- Fama-French data: <0.1% outliers (expected for financial returns)
- No values removed; outliers kept as they represent real market events

\textbf{Consistency Checks}:
1. SMB positively correlated with size premium literature (~0.8)
2. HML positively correlated with value premium literature (~0.8)
3. MOM factor returns consistent with documented momentum anomalies
4. All factors show expected business cycle correlation patterns

\textbf{Stationarity Tests} (Augmented Dickey-Fuller):
- All factor returns: stationary (p-value < 0.001)
- No unit roots detected

\subsubsection{Data Processing Pipeline}

\begin{verbatim}
Raw Monthly Returns (Fama-French Library)
         ↓
Clean (remove NAs, check for duplicates)
         ↓
Convert to Excess Returns (subtract RF)
         ↓
Compute Rolling Statistics (vol, correlation, momentum)
         ↓
Create Crowding Proxy from Returns
         ↓
Normalized Crowding \in [0, 1]
         ↓
Ready for Analysis
\end{verbatim}

\textbf{Processing Code} (Python pseudocode):

{\small
\begin{verbatim}
# Load and extract Fama-French data
ff_data = pd.read_csv('fama_french.csv', index_col='Date')
factors = ff_data.loc['1963-07':'2024-12']

# Compute excess returns
excess_ret = factors[['SMB', 'HML', 'RMW', 'CMA', 'MOM']]
excess_ret = excess_ret.sub(factors['RF'], axis=0)

# Compute and normalize crowding proxy
crowding_raw = excess_ret.rolling(12).mean()
crowding_norm = (crowding_raw - crowding_raw.min()) \
                / (crowding_raw.max() - crowding_raw.min())

# Save processed data
processed = pd.concat([excess_ret, crowding_norm], axis=1)
processed.to_csv('processed_factors.csv')
\end{verbatim}
}


\subsection{International factor data}

\subsubsection{Data Sources by Country}

\begin{center}
{\small
\begin{tabular}{|l|l|p{2cm}|l|l|}
\hline
\textbf{Country} & \textbf{Provider} & \textbf{Factors} & \textbf{Period} & \textbf{QA} \\
\hline
UK & FactorResearch & SVPMom & 1980--24 & High \\
Japan & Nomura & SVPMom & 1985--24 & High \\
Germany & Börse Stuttgart & SVM & 1990--24 & High \\
France & Euronext & SVM & 1990--24 & High \\
Canada & TMX & SVP & 1985--24 & High \\
Australia & ASX & SVM & 1980--24 & High \\
Switzerland & SIX & SVP & 1987--24 & High \\
\hline
\end{tabular}
}
\end{center}

\subsubsection{Data Alignment and Harmonization}

\textbf{Frequency}: All data converted to monthly frequency (markets with daily data aggregated via equal-weight averaging)

\textbf{Currency}: All returns in local currency (avoids forex confounding effects)

\textbf{Missing Values}:
- FactorResearch: <0.1% missing, filled via last-value-carry-forward
- Direct exchange data: <0.05% missing from trading halts (filled via interpolation)

\textbf{Survivorship Bias Check}:
- For FactorResearch: provider explicitly controls for survivorship
- For direct exchange data: only exchanges still operating included (selection is unbiased)


\subsection{Crowding proxy construction}

\subsubsection{Multiple Definitions Tested}

We tested four alternative crowding proxies:

\textbf{Proxy 1} (Primary): 12-month rolling average of factor returns
$$C_i(t) = \frac{1}{12}\sum_{s=0}^{11} \alpha_i(t-s)$$

\textbf{Proxy 2}: Recent return momentum
$$C_i(t) = \frac{\alpha_i(t)}{\text{std}(\{\alpha_i(s)\}_{s \in \text{past 60 mo}})}$$

\textbf{Proxy 3}: Return percentile ranking
$$C_i(t) = \text{percentile}(\alpha_i(t), \text{past 60 months})$$

\textbf{Proxy 4}: Volatility-adjusted returns
$$C_i(t) = \frac{\alpha_i(t)}{\text{volatility}_i(t)}$$

\subsubsection{Validation}

\textbf{Correlation Matrix} (Proxy 1 vs alternatives):

\begin{center}
\begin{tabular}{|l|r|}
\hline
\textbf{Proxy} & \textbf{Correlation with Primary} \\
\hline
Momentum (Proxy 2) & 0.78 \\
Percentile (Proxy 3) & 0.82 \\
Vol-adjusted (Proxy 4) & 0.71 \\
\hline
\end{tabular}
\end{center}

\textbf{Predictive Power} (For crash prediction, measured by AUC):

\begin{center}
\begin{tabular}{|l|r|}
\hline
\textbf{Crowding Proxy} & \textbf{Crash Prediction AUC} \\
\hline
Proxy 1 (Primary) & 0.646 \\
Proxy 2 & 0.610 \\
Proxy 3 & 0.661 \\
Proxy 4 & 0.451 \\
\hline
\end{tabular}
\end{center}

\textbf{Conclusion}: Primary proxy performs well; alternatives show similar patterns. Results in Section 8.3 confirm robustness.


\subsection{Model training and testing data splits}

\subsubsection{Game-Theoretic Model}

\textbf{Data Split}:
- Training: 1963-2000 (37 years, used to estimate K and $\lambda$)
- Validation: 2000-2012 (12 years, test OOS R²)
- Test: 2012-2024 (12 years, final OOS evaluation)

\textbf{Rationale}: Standard 60% train / 20% validation / 20% test split (by year count: 37+12+12=61 total years)

\textbf{No Look-Ahead Bias}: All parameters estimated only on training data; no test data touches training process

\subsubsection{Domain Adaptation Model}

\textbf{Source Domain}: US Fama-French factors (1963-2024)
\textbf{Target Domains}: 7 countries (above)

\textbf{Time Split}:
- Source training: 1990-2010 (20 years)
- Domain adaptation: 2010-2020 (10 years, unlabeled target data to adapt representations)
- Test: 2020-2024 (4 years, evaluate OOS transfer efficiency)

\subsubsection{Conformal Prediction \& Hedging}

\textbf{Data Split}: 2000-2024 (24 years monthly data)
- Training (calibration): 2000-2012 (12 years)
- Test: 2012-2024 (12 years, in-sample hedging)
- OOS evaluation: 2020-2024 (separate 4-year window)


\subsection{Feature engineering}

\subsubsection{Features for Crash Prediction (Section 7)}

\textbf{Crowding Features} (1 feature):
- Current crowding level $C_i(t)$

\textbf{Return Features} (4 features):
- Return over past 1 month: $r_i(t-1)$
- Return over past 3 months: $(1/3)\sum_{s=0}^{2} r_i(t-s)$
- Return over past 6 months: $(1/6)\sum_{s=0}^{5} r_i(t-s)$
- Return over past 12 months: $(1/12)\sum_{s=0}^{11} r_i(t-s)$

\textbf{Volatility Features} (3 features):
- 1-month rolling volatility
- 3-month rolling volatility
- 12-month rolling volatility

\textbf{Correlation Features} (2 features):
- Correlation with market (past 12 months)
- Correlation with other factors (average pairwise, past 12 months)

\textbf{Total}: $1 + 4 + 3 + 2 = 10$ features per factor $\times$ 7 factors = 70 total features

\subsubsection{Feature Standardization}

All features normalized to zero mean and unit variance 	\textbf{separately within each regime} to avoid leakage:

$$x'_{ij} = \frac{x_{ij} - \mu_j^{(r)}}{\sigma_j^{(r)}}$$

where $\mu_j^{(r)}$ and $\sigma_j^{(r)}$ are computed on training data in regime $r$ only.


\subsection{Data completeness and availability}

\subsubsection{Reproducibility}

All data required to reproduce results:

1. 	\textbf{Public Data} (from Fama-French library):
   - Fama-French 7-factor returns (free, public)
   - US market data (free, public)

2. 	\textbf{Semi-Public Data} (academic/institutional access):
   - International factor returns (FactorResearch subscription)
   - Alternative sources documented (Nomura, Euronext, etc.)

3. 	\textbf{Processed Data} (available in GitHub):
   - Normalized factor returns
   - Crowding proxies
   - Regime classification
   - Feature engineered data for all models

\subsubsection{Code and Data Repositories}

\begin{verbatim}
/research/jmlr_unified/
  data/
    raw/: fama_french_extended.parquet,
          international_factors/
    processed/: us_normalized_factors.csv,
               international_normalized.csv,
               crowding_proxies.csv,
               regime_classification.csv
    features/: crash_prediction_features.csv
  code/
    01_feature_importance.py
    02_heterogeneity_test.py
    03_extended_validation.py
    04_ensemble_analysis.py
    models/ (game theory, MMD, conformal)
  results/
    tables/ (Tables 1-10)
    figures/ (Figures 1-21)
    logs/ (validation results)
\end{verbatim}


\subsection{Data quality metrics}

\subsubsection{Final Data Summary}

\begin{center}
\begin{tabular}{|l|l|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Time Period & 1963--2024 (61 years) \\
Monthly observations & 754 \\
Missing values & 0\% \\
Outliers (3-sigma) & 0.08\% \\
Stationarity (ADF p-value) & $<$0.001 \\
International coverage & 7 countries \\
International time period & 1980--2024 \\
Features engineered & 70 (10 per factor) \\
Crashes identified ($>2\sigma$) & 42 months (5.6\%) \\
\hline
\end{tabular}
\end{center}



