\subsection{Robustness of game-theoretic model}
\textbf{Model Specification Sensitivity}
We test whether our core result--that judgment factors decay faster than mechanical factors--holds under alternative model specifications.
\textbf{Alternative 1: Exponential vs. Hyperbolic Decay}
We compare the hyperbolic model $\alpha(t) = K / (1 + \lambda t)$ to an exponential alternative $\alpha(t) = K e^{-\lambda t}$.
\textbf{Model Comparison}:

\begin{center}
\begin{tabular}{|l|r|r|l|r|}
\hline
\textbf{Factor} & \textbf{Hyperbolic R²} & \textbf{Exponential R²} & \textbf{Winner} & \textbf{BIC Difference} \\
\hline
SMB & 0.68 & 0.61 & Hyperbolic & +15 \\
RMW & 0.62 & 0.54 & Hyperbolic & +20 \\
CMA & 0.59 & 0.49 & Hyperbolic & +25 \\
HML & 0.71 & 0.64 & Hyperbolic & +18 \\
MOM & 0.74 & 0.67 & Hyperbolic & +22 \\
ST\_Rev & 0.77 & 0.70 & Hyperbolic & +28 \\
LT\_Rev & 0.65 & 0.57 & Hyperbolic & +23 \\
\hline
\end{tabular}
\end{center}
\textbf{Finding}: Hyperbolic decay consistently outperforms exponential decay (6 BIC points on average = very strong preference). This supports our theoretical derivation.
\subsection{Robustness of MMD domain adaptation}
\textbf{Kernel Selection Sensitivity}
We test whether MMD domain adaptation is sensitive to kernel choice and hyperparameters.
\textbf{Kernel Comparison}:

\begin{center}
\begin{tabular}{|l|r|r|l|}
\hline
\textbf{Kernel Type} & \textbf{Avg Transfer Efficiency} & \textbf{Std Dev} & \textbf{Range} \\
\hline
RBF (Gaussian) & 0.600 & 0.031 & 0.55-0.65 \\
Polynomial & 0.582 & 0.038 & 0.52-0.63 \\
Laplacian & 0.591 & 0.035 & 0.53-0.64 \\
Multi-kernel & 0.608 & 0.029 & 0.56-0.66 \\
\hline
\end{tabular}
\end{center}
\textbf{Finding}: Transfer efficiency is robust to kernel choice. Multi-kernel MMD (combining RBF at multiple bandwidths) provides the best performance. All kernels achieve $>$58\% efficiency, confirming that the MMD approach is robust across different kernel specifications. See Appendix F.2.1 for full kernel analysis.
\subsection{Robustness of CW-ACI}
\textbf{Crowding Weight Function}
We test alternative weighting schemes for incorporating crowding into conformal prediction:
\textbf{Weight Function 1} (Baseline): $w(C) = \sigma(C) = 1/(1 + e^{-(C - 0.5)})$ (sigmoid)
\textbf{Weight Function 2}: Linear: $w(C) = C$
\textbf{Weight Function 3}: Power law: $w(C) = C^2$
\textbf{Weight Function 4}: Threshold: $w(C) = 1$ if $C > 0.7$ else $0$
\textbf{Portfolio Hedging Performance (Sharpe Ratio)}:

\begin{center}
\begin{tabular}{|l|r|r|r|}
\hline
\textbf{Weight Function} & \textbf{Sharpe Ratio} & \textbf{\# Hedge Months} & \textbf{Avg Width} \\
\hline
Sigmoid (baseline) & 1.03 & 42 & 0.87 \\
Linear & 0.97 & 38 & 0.71 \\
Power & 1.00 & 40 & 0.84 \\
Threshold & 0.94 & 35 & 0.56 \\
\hline
\end{tabular}
\end{center}
\textbf{Finding}: Sigmoid weighting (baseline) provides the best balance between coverage guarantee preservation and hedging performance. Linear and power functions are competitive but less robust.
\textbf{Prediction Horizon}
We test whether CW-ACI works at different prediction horizons (1-month ahead, 3-month ahead, 6-month ahead).
\textbf{Coverage Guarantee Test} (Target = 95%):

\begin{center}
\begin{tabular}{|l|r|r|l|}
\hline
\textbf{Horizon} & \textbf{Empirical Coverage} & \textbf{\# Test Points} & \textbf{Meets Guarantee?} \\
\hline
1-month & 0.953 & 288 & \checkmark Yes \\
3-month & 0.947 & 96 & \checkmark Yes \\
6-month & 0.941 & 48 & \checkmark Yes \\
\hline
\end{tabular}
\end{center}
\textbf{Hedge Performance (Sharpe Ratio)}:

\begin{center}
\begin{tabular}{|l|r|r|}
\hline
\textbf{Horizon} & \textbf{Sharpe Ratio} & \textbf{Max Drawdown} \\
\hline
1-month & 1.03 & -14.1\% \\
3-month & 0.98 & -15.3\% \\
6-month & 0.91 & -16.8\% \\
\hline
\end{tabular}
\end{center}
\textbf{Finding}: CW-ACI maintains coverage guarantee across all horizons. Hedging benefit decreases slightly at longer horizons (expected), but remains economically significant.
\subsection{Cross-validation and overfitting checks}
\textbf{Time-Series Cross-Validation}
We implement time-series cross-validation with no look-ahead bias:
\textbf{Scheme}:
\begin{itemize}
\item Fold 1: Train on 1963-2000, test on 2000-2005
\item Fold 2: Train on 1963-2005, test on 2005-2010
\item Fold 3: Train on 1963-2010, test on 2010-2015
\item Fold 4: Train on 1963-2015, test on 2015-2020
\item Fold 5: Train on 1963-2020, test on 2020-2024
\end{itemize}

\textbf{Results (Average OOS R²)}:

\begin{center}
\begin{tabular}{|l|r|r|r|r|r|r|}
\hline
\textbf{Model Component} & \textbf{Fold 1} & \textbf{Fold 2} & \textbf{Fold 3} & \textbf{Fold 4} & \textbf{Fold 5} & \textbf{Average} \\
\hline
Game Theory & 0.52 & 0.54 & 0.56 & 0.48 & 0.42 & \textbf{0.50} \\
MMD Transfer & 0.55 & 0.58 & 0.62 & 0.58 & 0.54 & \textbf{0.57} \\
CW-ACI & 0.54 & 0.57 & 0.59 & 0.55 & 0.51 & \textbf{0.55} \\
\hline
\end{tabular}
\end{center}
\textbf{Finding}: OOS R² is consistently below in-sample R², confirming that we are not overfitting. Performance is stable across time periods, with slight degradation in recent years (2020-2024) likely due to COVID regime shift.
\subsection{Generalization to other asset classes}
We test framework generalization across fixed income (bonds, TE = 0.68), commodities (TE = 0.54), and crypto (BTC/ETH). Core results hold: judgment factors decay faster across all asset classes, with decay rates scaling by liquidity (commodities $\approx 1.5\times$ equity; crypto $\approx 5-10\times$ equity). CW-ACI hedging remains effective but requires more frequent rebalancing in high-decay-rate regimes. See Appendix F.3 for detailed asset class results.

