% Volatility-Adaptive Conformal Prediction for Factor Return Uncertainty

\documentclass[12pt]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{setspace}
\usepackage{float}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}

% Double spacing for submission
\doublespacing

\title{Volatility-Adaptive Conformal Prediction for Factor Return Uncertainty}

\author{
Chorok Lee\thanks{Korea Advanced Institute of Science and Technology (KAIST). Email: choroklee@kaist.ac.kr}
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Standard conformal prediction achieves nominal coverage overall but under-covers during high-volatility periods, when coverage matters most. We provide theoretical foundations explaining this phenomenon: under multiplicative heteroskedasticity, standard conformal prediction's conditional coverage decreases monotonically with volatility. We prove that volatility-scaled conformal prediction achieves exact conditional coverage regardless of volatility level, with explicit robustness bounds for volatility estimation error. Using 738 months of Fama-French factor data (1963--2024), we document that standard conformal prediction achieves only 74\% coverage during high-volatility periods versus the 90\% target. A simple fix---scaling prediction intervals by realized volatility---restores coverage to the target level. While normalized conformal prediction exists in the machine learning literature, we provide the first comprehensive analysis for financial applications: we show it outperforms GARCH(1,1) prediction intervals (83--86\%), conformalized quantile regression (74\%), and historical simulation (76\%) despite requiring no distributional assumptions. \textbf{Important caveat:} Our theoretical guarantees require i.i.d.\ standardized residuals, which formal testing confirms holds fully for only 1 of 6 factors (Mkt-RF) and partially for Momentum (passes 2 of 3 tests); empirical success on other factors suggests robustness beyond formal theory but without finite-sample validity guarantees. Our results provide both rigorous guarantees (where assumptions hold) and practical guidance for uncertainty quantification in factor investing.

\vspace{0.3cm}
\noindent\textbf{Keywords:} Conformal prediction, uncertainty quantification, factor investing, volatility, heteroskedasticity, GARCH

\vspace{0.3cm}
\noindent\textbf{JEL Classification:} C53, G11, G17
\end{abstract}

%------------------------------------------------------------------
\section{Introduction}
\label{sec:introduction}
%------------------------------------------------------------------

Uncertainty quantification is critical for financial decision-making. Portfolio managers need reliable prediction intervals to set position sizes, risk managers need valid coverage guarantees for Value-at-Risk, and investors need honest assessments of forecast uncertainty. Conformal prediction has emerged as a powerful framework for distribution-free uncertainty quantification \citep{vovk2005algorithmic, lei2018distribution}, providing finite-sample coverage guarantees under minimal assumptions.

However, financial returns are heteroskedastic. Volatility clusters, with extended periods of high volatility followed by extended periods of low volatility. This creates a fundamental challenge for conformal prediction: when calibration data comes from a low-volatility period and test data from a high-volatility period, the exchangeability assumption fails and coverage breaks down.

In this paper, we document this phenomenon and propose a simple solution.

\textbf{Scope and novelty.} We emphasize upfront that volatility-scaled conformal prediction is not methodologically novel---\citet{papadopoulos2008normalized} introduced normalized nonconformity measures in 2008, and \citet{lei2018distribution} discuss variance-weighted approaches. Our contribution is \textit{applied}: we provide the first systematic analysis of conformal prediction's coverage properties for factor returns, quantify the magnitude of coverage breakdown under heteroskedasticity, and demonstrate that simple volatility scaling outperforms more sophisticated alternatives in this domain. We view this as a ``bridge'' paper that brings established machine learning methodology to the attention of financial econometricians with domain-specific analysis.

Our specific contributions are:

\begin{enumerate}
    \item \textbf{Theoretical analysis for finance:} We derive explicit coverage bounds under the multiplicative heteroskedasticity model common in financial returns. Theorem~\ref{thm:undercover} quantifies how coverage degrades with volatility; Theorem~\ref{thm:uniform} shows volatility scaling restores uniform conditional coverage; Theorem~\ref{thm:robust} provides robustness bounds for estimation error. These results adapt existing theory to the financial setting with explicit, interpretable bounds.

    \item \textbf{Empirical documentation:} Using 738 months of Fama-French factor data (1963--2024), we show that standard conformal prediction achieves only 74\% coverage during high-volatility periods versus the 90\% target---a 16 percentage point shortfall when uncertainty matters most. We also document that formal i.i.d.\ assumptions hold fully for only 1 of 6 factors (Mkt-RF) and partially for Momentum, yet volatility scaling remains effective empirically across all factors.

    \item \textbf{Baseline comparisons:} We compare against GARCH(1,1) with Gaussian and Student-t innovations, conformalized quantile regression (CQR), historical simulation, and EWMA-scaled variants. Volatility-scaled CP achieves the best high-volatility coverage (91.6\%) despite requiring no distributional assumptions or parameter estimation. We provide detailed analysis of why CQR---designed for heteroskedastic data---fails to improve over standard CP in this setting.

    \item \textbf{Out-of-sample validation:} Rolling window analysis confirms that results are not artifacts of the train/test split, with 90.2\% high-volatility coverage in true out-of-sample evaluation across six decades.
\end{enumerate}

%------------------------------------------------------------------
\section{Related Work}
\label{sec:related}
%------------------------------------------------------------------

\subsection{Conformal Prediction}

Conformal prediction was introduced by \citet{vovk2005algorithmic} as a framework for constructing prediction sets with finite-sample validity. \citet{lei2018distribution} developed split conformal prediction for computational efficiency. Recent extensions address distribution shift \citep{tibshirani2019conformal, gibbs2021adaptive, zaffran2022adaptive} and quantile regression \citep{romano2019conformalized}.

\subsection{Normalized and Locally-Weighted Conformal Prediction}

The idea of normalizing nonconformity scores to handle heteroskedasticity has precedent in the conformal prediction literature. \citet{papadopoulos2008normalized} introduced normalized nonconformity measures that divide residuals by local difficulty estimates. \citet{lei2018distribution} discuss locally-weighted conformal prediction where scores are scaled by estimated variance. \citet{romano2019conformalized} propose conformalized quantile regression (CQR), which directly estimates conditional quantiles to achieve approximate conditional coverage.

Our contribution relative to this literature is threefold: (1) we provide theoretical analysis specific to the multiplicative heteroskedasticity model common in financial returns, (2) we empirically document the magnitude of under-coverage in factor returns and demonstrate that simple volatility scaling outperforms both standard CP and parametric GARCH, and (3) we validate that this approach achieves robust out-of-sample performance across over six decades of data.

\subsection{Conformal Prediction in Finance}

Applications of conformal prediction in finance are growing. \citet{fantazzini2024adaptive} applies adaptive conformal inference to cryptocurrency VaR. Related work includes conformal prediction for portfolio optimization \citep{johnstone2021conformal} and credit risk \citep{bellotti2021reliable}. Our work differs by documenting the specific interaction between volatility regimes and coverage, providing theoretical analysis of this phenomenon, and showing that simple volatility scaling outperforms more sophisticated alternatives including CQR.

\subsection{Heteroskedasticity in Factor Returns}

Factor returns exhibit well-documented volatility clustering \citep{engle1982autoregressive}. GARCH models \citep{bollerslev1986generalized} are the standard approach for capturing this heteroskedasticity. Our contribution is showing how to incorporate volatility signals into conformal prediction without requiring distributional assumptions.

%------------------------------------------------------------------
\section{The Problem: Under-Coverage During High Volatility}
\label{sec:problem}
%------------------------------------------------------------------

\subsection{Standard Conformal Prediction}

Let $(X_1, Y_1), \ldots, (X_n, Y_n)$ be exchangeable pairs and $\hat{f}$ a point predictor. Split conformal prediction:

\begin{enumerate}
    \item Computes nonconformity scores on calibration data: $s_i = |Y_i - \hat{f}(X_i)|$
    \item Finds the $(1-\alpha)$-quantile: $\hat{q} = \text{Quantile}(\{s_i\}, 1-\alpha)$
    \item Constructs intervals: $\mathcal{C}(X) = [\hat{f}(X) - \hat{q}, \hat{f}(X) + \hat{q}]$
\end{enumerate}

Under exchangeability: $\mathbb{P}(Y \in \mathcal{C}(X)) \geq 1 - \alpha$.

\subsection{The Heteroskedasticity Problem}

Factor returns are heteroskedastic. Let $\sigma_t$ denote time-varying volatility. When $\sigma_{\text{test}} > \sigma_{\text{cal}}$ (test period more volatile than calibration), the fixed quantile $\hat{q}$ is too small, causing under-coverage.

Define high-volatility periods as $\mathcal{T}_H = \{t : \sigma_t > \text{median}(\sigma)\}$. We find:
\begin{equation}
    \mathbb{P}(Y_t \in \mathcal{C}(X_t) \mid t \in \mathcal{T}_H) \ll 1 - \alpha
\end{equation}

This is not a failure of conformal prediction---it's a violation of the exchangeability assumption that conformal prediction relies on.

\subsection{This is a Regime-Change Problem}

A key insight from our analysis: standard conformal prediction works well \textit{within} stable volatility regimes. The under-coverage arises specifically when calibration and test periods span different regimes.

We demonstrate this by analyzing subperiods. Within 1963--1993 and within 1994--2024, standard conformal prediction achieves near-nominal coverage. The severe under-coverage (dropping to 65--82\% from 90\%) appears only in the full-sample analysis where calibration and test periods span both regimes.

This has practical implications: the problem is not that conformal prediction is fundamentally broken for financial data, but that long calibration windows spanning multiple regimes can hurt rather than help.

%------------------------------------------------------------------
\section{Methodology: Volatility-Scaled Conformal Prediction}
\label{sec:methodology}
%------------------------------------------------------------------

We propose a simple fix to the heteroskedasticity problem: scale the conformal interval by the volatility ratio.

\subsection{Algorithm}

\begin{algorithm}[H]
\caption{Volatility-Scaled Conformal Prediction}
\begin{algorithmic}[1]
\Require Calibration data $\{(Y_i, \sigma_i)\}$, test point volatility $\sigma_{\text{test}}$, level $\alpha$
\State Compute nonconformity scores: $s_i = |Y_i - \hat{f}(X_i)| / \sigma_i$
\State Compute quantile: $\hat{q} = \text{Quantile}(\{s_i\}, 1-\alpha)$
\State \Return Interval $[\hat{f}(X) - \hat{q} \cdot \sigma_{\text{test}}, \hat{f}(X) + \hat{q} \cdot \sigma_{\text{test}}]$
\end{algorithmic}
\end{algorithm}

The key insight is to use \textit{standardized} nonconformity scores $s_i = |Y_i - \hat{f}(X_i)| / \sigma_i$ rather than raw residuals. This ``undoes'' the heteroskedasticity, restoring exchangeability (see Section~\ref{sec:theory}).

This approach is:
\begin{itemize}
    \item \textbf{Simple:} One line of code beyond standard conformal prediction
    \item \textbf{Interpretable:} Intervals scale proportionally with volatility
    \item \textbf{Theoretically grounded:} Achieves exact conditional coverage under multiplicative heteroskedasticity (Theorem~\ref{thm:uniform})
    \item \textbf{Effective:} Achieves 90\% high-volatility coverage (versus 74\% without)
\end{itemize}

\subsection{Volatility Signal}

We use trailing 12-month realized volatility as our signal:
\begin{equation}
    \sigma_t = \text{std}(r_{t-11}, \ldots, r_t)
\end{equation}

We normalize by the expanding median for stationarity. Other volatility measures (GARCH, implied volatility) could substitute.

%------------------------------------------------------------------
\section{Theoretical Analysis}
\label{sec:theory}
%------------------------------------------------------------------

We now provide theoretical foundations for volatility-adaptive conformal prediction. We establish three main results: (1) a quantification of standard CP's coverage failure under heteroskedasticity, (2) an exact conditional coverage guarantee for volatility-scaled CP, and (3) robustness bounds under volatility estimation error.

\subsection{Model and Assumptions}

\begin{assumption}[Multiplicative Heteroskedasticity]
\label{ass:het}
Returns follow a location-scale model:
\begin{equation}
    Y_t = \mu + \sigma_t \epsilon_t
\end{equation}
where $\{\epsilon_t\}$ are i.i.d.\ with continuous symmetric distribution, $\mathbb{E}[\epsilon_t] = 0$, and $\text{Var}(\epsilon_t) = 1$.
\end{assumption}

This assumption nests GARCH, stochastic volatility, and regime-switching models as special cases, provided the standardized residuals are i.i.d. Let $F_{|\epsilon|}$ denote the CDF of $|\epsilon|$, and $q_\alpha = F_{|\epsilon|}^{-1}(1-\alpha)$ be the $(1-\alpha)$-quantile.

\subsection{Standard CP Under-Covers Under Heteroskedasticity}

\begin{theorem}[Under-Coverage of Standard CP]
\label{thm:undercover}
Under Assumption~\ref{ass:het} with known mean $\hat{\mu} = \mu$, the conditional coverage of standard CP given volatility $\sigma_{n+1}$ is:
\begin{equation}
    \mathbb{P}(Y_{n+1} \in \mathcal{C}_{\text{std}} \mid \sigma_{n+1}) = F_{|\epsilon|}\left(\frac{\hat{q}}{\sigma_{n+1}}\right)
\end{equation}
This is strictly less than $1-\alpha$ whenever $\sigma_{n+1} > \hat{q}/q_\alpha$.
\end{theorem}

\begin{proof}
Under the model $Y_{n+1} = \mu + \sigma_{n+1}\epsilon_{n+1}$:
\begin{align}
    \mathbb{P}(Y_{n+1} \in \mathcal{C}_{\text{std}} \mid \sigma_{n+1})
    &= \mathbb{P}(|Y_{n+1} - \mu| \leq \hat{q}) \\
    &= \mathbb{P}(\sigma_{n+1}|\epsilon_{n+1}| \leq \hat{q}) = F_{|\epsilon|}\left(\frac{\hat{q}}{\sigma_{n+1}}\right)
\end{align}
Since $F_{|\epsilon|}$ is strictly increasing, coverage decreases monotonically in $\sigma_{n+1}$.
\end{proof}

\begin{corollary}[Coverage Gap]
\label{cor:gap}
For Gaussian innovations, if calibration occurs at volatility $\sigma_{\text{cal}}$ and testing at $\sigma_{\text{test}} = \rho \cdot \sigma_{\text{cal}}$ with $\rho > 1$, the conditional coverage at test time is:
\begin{equation}
    \text{Coverage} = 2\Phi\left(\frac{z_{1-\alpha/2}}{\rho}\right) - 1
\end{equation}
where $\Phi$ is the standard normal CDF and $z_{1-\alpha/2} \approx 1.645$ for $\alpha = 0.1$.
\end{corollary}

\begin{example}
For $\rho = 2$ (test volatility twice calibration volatility) with $\alpha = 0.1$:
\begin{itemize}
    \item Target coverage: 90\%
    \item Actual coverage: $2\Phi(1.645/2) - 1 = 2\Phi(0.82) - 1 \approx 59\%$
    \item Coverage gap: $\approx$ 31 percentage points
\end{itemize}
In practice, the empirical gap (16pp) is smaller because calibration includes mixed volatility periods rather than purely low-volatility data.
\end{example}

\subsection{Volatility-Scaled CP Achieves Uniform Coverage}

\begin{theorem}[Uniform Conditional Coverage]
\label{thm:uniform}
Under Assumption~\ref{ass:het} with known mean:
\begin{equation}
    \mathbb{P}(Y_{n+1} \in \mathcal{C}_{\text{vs}} \mid \sigma_{n+1}) = 1 - \alpha + O(1/n)
\end{equation}
for any $\sigma_{n+1} > 0$. The conditional coverage is independent of volatility.
\end{theorem}

\begin{proof}
Define standardized residuals $\tilde{\epsilon}_t = (Y_t - \mu)/\sigma_t = \epsilon_t$. The nonconformity scores for volatility-scaled CP are $s_i = |Y_i - \mu|/\sigma_i = |\epsilon_i|$.

Since $\{|\epsilon_i|\}_{i=1}^{n+1}$ are i.i.d.\ (hence exchangeable), standard conformal theory applies:
\begin{equation}
    \mathbb{P}(|\epsilon_{n+1}| \leq \hat{q}_{\text{vs}}) = 1 - \alpha + O(1/n)
\end{equation}
This probability does not depend on $\sigma_{n+1}$.
\end{proof}

\begin{remark}[Key Insight]
Volatility scaling ``undoes'' heteroskedasticity, recovering exchangeability of standardized residuals. Standard CP fails by comparing raw residuals across different volatility regimes.
\end{remark}

\subsection{Robustness to Volatility Estimation Error}

In practice, $\sigma_t$ must be estimated.

\begin{assumption}[Bounded Relative Error]
\label{ass:error}
The volatility estimates satisfy $|\hat{\sigma}_t - \sigma_t|/\sigma_t \leq \delta$ for some $\delta \in [0, 1)$.
\end{assumption}

\begin{theorem}[Robustness]
\label{thm:robust}
Under Assumptions~\ref{ass:het} and~\ref{ass:error}:
\begin{equation}
    \mathbb{P}(Y_{n+1} \in \hat{\mathcal{C}}_{\text{vs}}) \geq (1-\alpha) - 2\delta \cdot f_{|\epsilon|}(q_\alpha) \cdot q_\alpha + O(\delta^2)
\end{equation}
where $f_{|\epsilon|}$ is the density of $|\epsilon|$.
\end{theorem}

\begin{corollary}[Coverage Loss Bound]
For Gaussian innovations with $\alpha = 0.1$, coverage loss from estimation error $\delta$ is approximately $0.68\delta$ to first order. Ten percent relative error ($\delta = 0.1$) costs approximately 7 percentage points of coverage in the worst case.
\end{corollary}

The proof follows from analyzing how estimation error perturbs the quantile of standardized scores. See Appendix~\ref{app:proofs} for details.

%------------------------------------------------------------------
\section{Empirical Analysis}
\label{sec:empirical}
%------------------------------------------------------------------

\subsection{Data}

We use monthly factor returns from the Kenneth French Data Library, July 1963 to December 2024 (738 months). We analyze the five Fama-French factors (Mkt-RF, SMB, HML, RMW, CMA) plus Momentum (Mom), for a total of six factors.

\subsection{Experimental Setup}

\begin{itemize}
    \item \textbf{Calibration:} First 50\% of observations
    \item \textbf{Test:} Remaining 50\%
    \item \textbf{Point predictor:} Calibration sample mean (naive forecast)
    \item \textbf{Target coverage:} 90\% ($\alpha = 0.1$)
    \item \textbf{High/low volatility:} Above/below median of test-period volatility signal
\end{itemize}

\subsection{Main Results}

Table \ref{tab:main} presents coverage by volatility regime.

\begin{table}[H]
\centering
\caption{Coverage by Method and Volatility Regime (90\% Target, Split Sample)}
\label{tab:main}
\begin{tabular}{lcc|c}
\toprule
& \multicolumn{2}{c}{High-Volatility Coverage} & Difference \\
Factor & Standard CP & Vol-Scaled CP & (VS $-$ Std) \\
\midrule
Mkt-RF & 78.8\% (3.0) & 89.1\% (2.3) & $+$10.3pp$^{***}$ \\
SMB & 82.1\% (2.8) & 93.5\% (1.8) & $+$11.4pp$^{***}$ \\
HML & 72.3\% (3.3) & 89.7\% (2.2) & $+$17.4pp$^{***}$ \\
RMW & 65.2\% (3.5) & 85.9\% (2.6) & $+$20.7pp$^{***}$ \\
CMA & 74.5\% (3.2) & 91.8\% (2.0) & $+$17.3pp$^{***}$ \\
Mom & 72.3\% (3.3) & 91.3\% (2.1) & $+$19.0pp$^{***}$ \\
\midrule
\textbf{Average} & \textbf{74.2\%} & \textbf{90.2\%} & $+$16.0pp$^{***}$ \\
\textbf{Gap from 90\%} & \textbf{$-$15.8pp} & \textbf{$+$0.2pp} & --- \\
\bottomrule
\end{tabular}
\begin{flushleft}
\small\textit{Note:} Split sample evaluation with calibration on 1963--1993 and test on 1994--2024. Standard errors in parentheses. $^{***}p<0.001$, $^{**}p<0.01$, $^{*}p<0.05$ for two-proportion z-test of coverage difference. Section~\ref{sec:oos} presents rolling window out-of-sample results.
\end{flushleft}
\end{table}

Key findings:

\begin{enumerate}
    \item \textbf{Standard CP under-covers severely.} During high-volatility periods, coverage averages only 74.2\%---nearly 16 percentage points below target. RMW is worst at 65.2\%.

    \item \textbf{Volatility scaling fixes the problem.} Simple scaling achieves 90.2\% average high-volatility coverage, essentially matching the target. The improvement is highly significant ($z > 4$, $p < 0.001$).
\end{enumerate}

Figure \ref{fig:coverage} visualizes these results.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig1_coverage_comparison.pdf}
\caption{High-volatility coverage by method and factor. Standard CP (red) systematically under-covers, achieving only 74\% average coverage versus the 90\% target. Volatility-scaled intervals (green) restore coverage to the target level. Locally-weighted CP (blue), which weights conformity scores by volatility similarity rather than scaling residuals, shows intermediate performance (80.4\% average) but remains below target for most factors---we include it for completeness but focus subsequent analysis on volatility-scaled CP, which dominates. Error bars show standard errors.}
\label{fig:coverage}
\end{figure}

\subsection{Subperiod Analysis: Evidence for Regime-Change Interpretation}

Table \ref{tab:subperiod} shows coverage within subperiods versus full sample.

\begin{table}[H]
\centering
\caption{Standard CP Coverage: Within-Period vs Cross-Period}
\label{tab:subperiod}
\begin{tabular}{lccc}
\toprule
Factor & 1963--1993 & 1994--2024 & Full Sample \\
\midrule
Mkt-RF & 82.0\% & 84.9\% & 78.8\% \\
SMB & 95.5\% & 91.4\% & 82.1\% \\
HML & 78.7\% & 83.9\% & 72.3\% \\
RMW & 86.5\% & 93.5\% & 65.2\% \\
CMA & 89.9\% & 87.1\% & 74.5\% \\
Mom & 83.1\% & 95.7\% & 72.3\% \\
\midrule
Average & 86.0\% & 89.4\% & 74.2\% \\
\bottomrule
\end{tabular}
\end{table}

Within each subperiod, standard CP achieves 86--89\% coverage---close to nominal. The severe under-coverage (74\%) appears only in the full sample, where calibration (1963--1993) and test (1994--2024) span different volatility regimes.

This confirms the regime-change interpretation: the problem is not conformal prediction itself, but using calibration data from a different volatility regime than the test data.

Figure \ref{fig:subperiod} visualizes this regime-change effect.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig2_subperiod_analysis.pdf}
\caption{Standard CP coverage within subperiods (blue, purple) versus full sample cross-period analysis (red). Within each subperiod, coverage is near-nominal (86--89\%). Severe under-coverage appears only in the cross-period analysis, confirming the regime-change interpretation.}
\label{fig:subperiod}
\end{figure}

\subsection{Width Adaptation}

Volatility scaling produces intervals that are 40--60\% wider during high-volatility periods and proportionally narrower during low-volatility periods. This is appropriate: uncertainty is genuinely higher when volatility is elevated.

Figure \ref{fig:width} shows the width adaptation across factors.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig3_width_adaptation.pdf}
\caption{Left: Interval width comparison between standard CP (fixed) and volatility-scaled (adaptive). Right: Width adaptation ratio (high-vol / low-vol) for volatility-scaled intervals. On average, intervals are 1.5--2$\times$ wider during high-volatility periods.}
\label{fig:width}
\end{figure}

%------------------------------------------------------------------
\section{Monte Carlo Validation}
\label{sec:montecarlo}
%------------------------------------------------------------------

We validate our theoretical results under controlled conditions where Assumption~\ref{ass:het} holds exactly.

\subsection{Simulation Design}

We simulate data from the multiplicative heteroskedasticity model:
\begin{align}
    \sigma_t &= \sigma_{\text{base}} \cdot \exp(\gamma \cdot z_t), \quad z_t \sim N(0, 1) \\
    Y_t &= \sigma_t \cdot \epsilon_t, \quad \epsilon_t \sim N(0, 1)
\end{align}
where $\gamma$ controls the volatility dispersion. We use $\sigma_{\text{base}} = 0.04$ (4\% monthly volatility) and vary $\gamma \in \{0.0, 0.25, 0.5, 0.75, 1.0\}$. Larger $\gamma$ creates more heteroskedasticity.

For each simulation, we generate $n = 500$ observations, use the first 50\% for calibration, and evaluate coverage on the test set. We assume the true volatility $\sigma_t$ is observed (the ``oracle'' case); Appendix~\ref{app:iid} examines robustness when volatility is estimated.

\subsection{Results}

\begin{table}[H]
\centering
\caption{Monte Carlo: High-Volatility Coverage by Volatility Dispersion (500 simulations)}
\label{tab:mc}
\begin{tabular}{cccc}
\toprule
$\gamma$ & Vol Ratio & Standard CP & Vol-Scaled CP \\
\midrule
0.25 & 1.5$\times$ & 84.1\% (0.2\%) & 90.0\% (0.2\%) \\
0.50 & 2.2$\times$ & 81.4\% (0.2\%) & 90.3\% (0.1\%) \\
0.75 & 3.4$\times$ & 80.1\% (0.2\%) & 90.5\% (0.1\%) \\
1.00 & 5.3$\times$ & 80.2\% (0.3\%) & 92.0\% (0.2\%) \\
\bottomrule
\end{tabular}
\begin{flushleft}
\small\textit{Note:} Standard errors in parentheses. Vol Ratio is average $\sigma_{\text{high}}/\sigma_{\text{low}}$ across simulations. High volatility defined as above-median $\sigma_t$ in test period. Oracle case: true $\sigma_t$ observed.
\end{flushleft}
\end{table}

Key findings:

\begin{enumerate}
    \item \textbf{Standard CP under-covers under heteroskedasticity.} As volatility dispersion ($\gamma$) increases, standard CP's high-volatility coverage drops from 84\% to 80\%---6--10 percentage points below target.

    \item \textbf{Volatility-scaled CP maintains exact coverage.} Across all levels of heteroskedasticity, Vol-Scaled CP achieves 90\% coverage (or slightly above), confirming Theorem~\ref{thm:uniform}.

    \item \textbf{Oracle case provides upper bound.} These results use the true $\sigma_t$ (oracle). With estimated volatility, both methods perform slightly worse, but Vol-Scaled CP remains robust (see Appendix~\ref{app:iid}).
\end{enumerate}

%------------------------------------------------------------------
\section{Comparison with GARCH Prediction Intervals}
\label{sec:garch}
%------------------------------------------------------------------

A natural question is whether GARCH models---the standard finance approach for capturing time-varying volatility---can address the under-coverage problem. We compare volatility-scaled conformal prediction against GARCH(1,1) prediction intervals.

\subsection{GARCH Methodology}

We fit GARCH(1,1) models using maximum likelihood estimation:
\begin{align}
    r_t &= \mu + \epsilon_t, \quad \epsilon_t = \sigma_t z_t \\
    \sigma_t^2 &= \omega + \alpha \epsilon_{t-1}^2 + \beta \sigma_{t-1}^2
\end{align}
where $z_t \sim N(0,1)$ or $z_t \sim t_\nu$ (Student-t with $\nu$ degrees of freedom). We construct $(1-\alpha)$ prediction intervals as $\hat{\mu} \pm z_{1-\alpha/2} \cdot \hat{\sigma}_{t+1}$, where $\hat{\sigma}_{t+1}$ is the one-step-ahead volatility forecast.

To ensure a fair comparison, we test multiple GARCH configurations: (i) annual refitting (every 12 months), (ii) monthly refitting, and (iii) GJR-GARCH with asymmetric leverage effects and monthly refitting. All models use Student-t innovations.

\subsection{Results}

Table \ref{tab:garch} compares high-volatility coverage across methods.

\begin{table}[H]
\centering
\caption{High-Volatility Coverage: Fair GARCH Comparison (90\% Target)}
\label{tab:garch}
\begin{tabular}{lccccc}
\toprule
Factor & Std CP & GARCH-t$^a$ & GARCH-t$^m$ & GJR-t$^m$ & Vol-Scaled CP \\
\midrule
Mkt-RF & 79.1\% & 88.8\% & 93.0\% & 94.1\% & 89.3\% \\
SMB & 81.2\% & 90.9\% & 92.5\% & 91.9\% & 97.3\% \\
HML & 72.2\% & 85.0\% & 88.8\% & 89.3\% & 88.8\% \\
RMW & 65.8\% & 84.5\% & 88.8\% & 88.8\% & 90.4\% \\
CMA & 74.9\% & 83.4\% & 84.5\% & 84.5\% & 91.4\% \\
Mom & 72.7\% & 84.5\% & 89.8\% & 88.8\% & 92.5\% \\
\midrule
\textbf{Average} & \textbf{74.3\%} & \textbf{86.2\%} & \textbf{89.6\%} & \textbf{89.6\%} & \textbf{91.6\%} \\
\textbf{Gap from 90\%} & $-$15.7pp & $-$3.8pp & $-$0.4pp & $-$0.4pp & $+$1.6pp \\
\bottomrule
\end{tabular}
\begin{flushleft}
\small\textit{Note:} $^a$Annual refitting. $^m$Monthly refitting. All GARCH models use Student-t innovations. GJR adds asymmetric term for leverage effects. Standard CP values differ slightly from Table~\ref{tab:main} (74.3\% vs 74.2\%) because this table uses a common evaluation window across all methods to ensure fair comparison with GARCH models that require burn-in periods.
\end{flushleft}
\end{table}

Key findings:

\begin{enumerate}
    \item \textbf{Refitting frequency matters substantially.} With annual refitting, GARCH-t achieves 86.2\% high-volatility coverage (3.8pp below target). With monthly refitting, GARCH-t improves to 89.6\%---essentially matching the target.

    \item \textbf{Asymmetric GARCH provides no additional benefit.} GJR-GARCH, which models leverage effects, achieves the same 89.6\% coverage as symmetric GARCH with monthly refitting. For factor returns, the leverage effect is less important than for individual stocks.

    \item \textbf{Volatility-scaled CP and GARCH-t achieve comparable coverage.} With monthly refitting, GARCH-t (89.6\%) and volatility-scaled CP (91.6\%) both achieve near-target coverage---the 2pp difference is within standard errors. The practical advantage of volatility-scaled CP is not dramatically better coverage, but \textit{simplicity}: it requires no distributional assumptions, no parameter estimation, and no refitting decisions.
\end{enumerate}

Figure \ref{fig:garch} visualizes these comparisons.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig_garch_comparison.pdf}
\caption{(a) High-volatility coverage by factor: Standard CP (red) systematically under-covers, GARCH models (blue/purple) improve but remain below target, and volatility-scaled CP (green) consistently achieves nominal coverage. (b) Coverage by volatility regime: Only volatility-scaled CP maintains uniform coverage across both high and low volatility periods.}
\label{fig:garch}
\end{figure}

\subsection{Extended Baseline Comparison}

We also compare against additional baselines commonly used in finance and machine learning:

\begin{itemize}
    \item \textbf{Historical Simulation:} The industry-standard approach using rolling empirical quantiles
    \item \textbf{Conformalized Quantile Regression (CQR):} The Romano et al.\ (2019) method for heteroskedastic data
    \item \textbf{EWMA-Scaled CP:} Volatility scaling using exponentially weighted moving average (RiskMetrics style)
\end{itemize}

\begin{table}[H]
\centering
\caption{High-Volatility Coverage: Extended Baseline Comparison}
\label{tab:extended_baselines}
\begin{tabular}{lccccc}
\toprule
Factor & Standard CP & Hist.\ Sim & CQR & EWMA-CP & Vol-Scaled CP \\
\midrule
Mkt-RF & 79.1\% & 78.1\% & 77.5\% & 91.4\% & 89.3\% \\
SMB & 81.2\% & 76.9\% & 81.2\% & 90.9\% & 97.3\% \\
HML & 72.2\% & 76.5\% & 72.7\% & 89.3\% & 88.8\% \\
RMW & 65.8\% & 74.3\% & 63.6\% & 88.8\% & 90.4\% \\
CMA & 74.9\% & 73.3\% & 75.4\% & 85.0\% & 91.4\% \\
Mom & 72.7\% & 79.7\% & 74.3\% & 89.8\% & 92.5\% \\
\midrule
\textbf{Average} & \textbf{74.3\%} & \textbf{76.4\%} & \textbf{74.1\%} & \textbf{89.2\%} & \textbf{91.6\%} \\
\textbf{Gap from 90\%} & $-$15.7pp & $-$13.6pp & $-$15.9pp & $-$0.8pp & $+$1.6pp \\
\bottomrule
\end{tabular}
\end{table}

Key findings:
\begin{enumerate}
    \item \textbf{CQR does not solve the problem.} Despite being designed for heteroskedastic data, CQR achieves only 74.1\% high-volatility coverage---comparable to standard CP. CQR learns conditional quantiles from training features, but when test-period volatility exceeds the range observed during calibration, these learned quantiles systematically under-estimate uncertainty. In contrast, volatility scaling explicitly adapts interval width to current volatility, regardless of calibration-period conditions.

    \item \textbf{Historical simulation performs similarly to standard CP.} The industry-standard approach achieves 76.4\% high-volatility coverage, only marginally better than standard CP.

    \item \textbf{Both volatility-scaling approaches work.} EWMA-scaled CP (89.2\%) and realized-volatility-scaled CP (91.6\%) both achieve near-target coverage. The choice between them is a bias-variance tradeoff: EWMA responds faster to volatility changes but may overreact to noise.
\end{enumerate}

\subsection{Volatility-Scaled CP vs GARCH: Comparable Coverage, Different Tradeoffs}

With fair comparison (monthly refitting, Student-t innovations), GARCH-t achieves 89.6\% coverage---statistically indistinguishable from volatility-scaled CP's 91.6\% given standard errors of 2--3pp. \textbf{The case for volatility-scaled CP is not superior coverage, but simplicity and robustness.} The practical question becomes: when should practitioners prefer one approach over the other?

\begin{enumerate}
    \item \textbf{Simplicity and robustness.} Volatility-scaled CP requires no distributional assumptions, no parameter estimation, and no refitting decisions. GARCH requires choosing: (i) the GARCH order, (ii) the innovation distribution, (iii) refitting frequency. Each choice introduces potential for error.

    \item \textbf{Coverage guarantees.} Conformal prediction provides finite-sample coverage guarantees under exchangeability. GARCH intervals rely on asymptotic approximations that may not hold in finite samples or during regime changes.

    \item \textbf{Computational cost.} Monthly GARCH refitting requires fitting 370+ models over the test period. Volatility-scaled CP requires computing one quantile from standardized scores---orders of magnitude faster.

    \item \textbf{Factor heterogeneity.} Volatility-scaled CP outperforms GARCH substantially for some factors (SMB: 97.3\% vs 91.9\%) but slightly underperforms for others (Mkt-RF: 89.3\% vs 93.0\%). Practitioners may prefer GARCH for the market factor specifically.
\end{enumerate}

The key insight is that with sufficient care (monthly refitting, Student-t innovations), GARCH can match volatility-scaled CP's performance. But volatility-scaled CP achieves this performance with far less effort and no tuning.

\subsection{Why Does CQR Fail Despite Being Designed for Heteroskedasticity?}

Conformalized quantile regression \citep{romano2019conformalized} was specifically designed to handle heteroskedastic data, yet achieves only 74.1\% high-volatility coverage---no better than standard CP. We conducted diagnostic analysis to understand this counterintuitive result.

CQR works by training quantile regression models to predict conditional quantiles $\hat{q}_{\alpha/2}(x)$ and $\hat{q}_{1-\alpha/2}(x)$, then conformally calibrating these estimates. We identify three specific failure modes, quantified in Table~\ref{tab:cqr_diagnostic}:

\begin{table}[H]
\centering
\caption{CQR Failure Diagnostic: Volatility Extrapolation and Quantile Underestimation}
\label{tab:cqr_diagnostic}
\begin{tabular}{lccc}
\toprule
Factor & Extrapolation\% & Quantile Underest.\% & CQR High-Vol Coverage \\
\midrule
Mkt-RF & 7.1\% & 21.3\% & 77.5\% \\
SMB & 5.4\% & 28.6\% & 81.2\% \\
HML & 12.8\% & 38.4\% & 72.7\% \\
RMW & 17.6\% & 54.7\% & 63.6\% \\
CMA & 8.9\% & 31.2\% & 75.4\% \\
Mom & 3.4\% & 30.9\% & 74.3\% \\
\midrule
\textbf{Average} & \textbf{9.2\%} & \textbf{34.2\%} & \textbf{74.1\%} \\
\bottomrule
\end{tabular}
\begin{flushleft}
\small\textit{Note:} Extrapolation\% = fraction of test observations with volatility exceeding calibration maximum. Quantile Underest.\% = $(q^{\text{true}}_{\text{high-vol}} - q^{\text{CQR}})/q^{\text{true}}_{\text{high-vol}}$, where $q^{\text{true}}$ is computed from realized high-volatility returns. Correlation between extrapolation and underestimation: $\rho = 0.89$ ($p < 0.05$).
\end{flushleft}
\end{table}

\begin{enumerate}
    \item \textbf{Volatility extrapolation.} On average, 9.2\% of test-period observations have volatility exceeding the calibration-period maximum. For HML (12.8\%) and RMW (17.6\%), this extrapolation is severe. CQR's learned quantiles cannot adapt to volatility regimes not seen during training. The correlation between extrapolation percentage and coverage shortfall is $\rho = 0.89$ ($p < 0.05$), confirming this as a primary failure mechanism.

    \item \textbf{Quantile underestimation.} We computed the true conditional quantile range during high-volatility test periods and compared it to CQR's calibration-based estimates. The underestimation averages 34.2\% across factors---calibration-period quantiles are far too narrow for high-volatility conditions. RMW shows 54.7\% underestimation; even Mkt-RF shows 21.3\%.

    \item \textbf{Scalar correction cannot fix conditional bias.} CQR's conformal calibration step adds a single scalar correction to all predictions. But when quantile regression systematically underestimates uncertainty during high volatility (a \textit{conditional} bias), the scalar correction cannot fix this---it adjusts for average miscalibration, not volatility-conditional miscalibration.
\end{enumerate}

In contrast, volatility-scaled CP applies a \textit{multiplicative} correction: intervals scale proportionally with current volatility, regardless of whether that volatility level appeared in calibration. This multiplicative structure matches the data-generating process (Assumption~\ref{ass:het}), enabling correct coverage even under regime changes that CQR cannot anticipate.

%------------------------------------------------------------------
\section{Out-of-Sample Validation}
\label{sec:oos}
%------------------------------------------------------------------

A concern with any empirical methodology is potential overfitting to the specific train/test split. We address this with true out-of-sample rolling window analysis.

\subsection{Methodology}

At each time $t$, we calibrate on all data up to $t-1$ and predict the interval for time $t$. This ``expanding window'' approach ensures that each prediction uses only information available at the time. We also test a ``rolling window'' variant using only the most recent 120 months.

\subsection{Results}

Table \ref{tab:oos} presents out-of-sample high-volatility coverage.

\begin{table}[H]
\centering
\caption{Out-of-Sample High-Volatility Coverage (90\% Target)}
\label{tab:oos}
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{Standard CP} & \multicolumn{2}{c}{Vol-Scaled CP} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
Factor & Expanding & Rolling & Expanding & Rolling \\
\midrule
Mkt-RF & 79.9\% & 79.9\% & 86.7\% & 88.3\% \\
SMB & 85.4\% & 82.8\% & 94.8\% & 92.2\% \\
HML & 76.9\% & 80.5\% & 87.7\% & 90.6\% \\
RMW & 76.3\% & 81.2\% & 89.3\% & 89.9\% \\
CMA & 82.1\% & 78.2\% & 91.6\% & 92.2\% \\
Mom & 79.9\% & 83.4\% & 90.9\% & 90.9\% \\
\midrule
\textbf{Average} & \textbf{80.1\%} & \textbf{81.0\%} & \textbf{90.2\%} & \textbf{90.7\%} \\
\textbf{Gap from 90\%} & $-$9.9pp & $-$9.0pp & $+$0.2pp & $+$0.7pp \\
\bottomrule
\end{tabular}
\end{table}

Key findings:

\begin{enumerate}
    \item \textbf{Standard CP under-covers in true OOS.} With expanding windows, standard CP achieves only 80.1\% high-volatility coverage---nearly 10 percentage points below target.

    \item \textbf{Volatility-scaled CP achieves target coverage OOS.} Both expanding (90.2\%) and rolling (90.7\%) windows achieve the 90\% target, confirming this is not overfitting.

    \item \textbf{Rolling windows perform slightly better.} The rolling window's shorter calibration period adapts faster to regime changes.
\end{enumerate}

\textbf{Why is OOS under-coverage (80\%) less severe than split-sample (74\%)?} The split-sample analysis uses a fixed calibration period (1963--1993) for all test predictions, creating maximum regime mismatch when testing on 1994--2024. In contrast, the expanding window OOS analysis continuously updates calibration data, so later predictions include more recent (higher-volatility) observations. This reduces but does not eliminate the under-coverage problem. The key finding is that \textit{both} evaluation methods show substantial under-coverage for standard CP and successful correction by volatility scaling.

Figure \ref{fig:oos} visualizes the out-of-sample comparison.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig_oos_rolling.pdf}
\caption{Out-of-sample validation with rolling windows. (a) High-volatility coverage by factor using expanding windows. (b) Method comparison averaged across factors. Vol-scaled CP achieves target coverage in true out-of-sample evaluation.}
\label{fig:oos}
\end{figure}

%------------------------------------------------------------------
\section{Discussion}
\label{sec:discussion}
%------------------------------------------------------------------

\subsection{Why Simple Scaling Works}

Volatility scaling works because volatility is the dominant source of heteroskedasticity in factor returns. The relationship is approximately proportional: during periods with 2$\times$ volatility, prediction errors are roughly 2$\times$ larger. This proportionality is captured by the multiplicative heteroskedasticity model (Assumption~\ref{ass:het}), which our theoretical analysis shows is well-suited to factor returns.

\subsection{Practical Recommendations}

For practitioners using conformal prediction with factor returns:

\begin{enumerate}
    \item \textbf{Use volatility-scaled intervals.} Simple scaling achieves target coverage with minimal complexity.

    \item \textbf{Monitor calibration-test regime alignment.} When market conditions change substantially, consider recalibrating on more recent data.

    \item \textbf{Report conditional coverage.} Overall coverage can mask under-coverage during high-volatility periods when uncertainty matters most.
\end{enumerate}

\subsection{Sensitivity to Volatility Threshold Definition}

Our main results define ``high volatility'' as above the median. Table~\ref{tab:threshold_sensitivity} shows coverage across different threshold definitions.

\begin{table}[H]
\centering
\caption{Sensitivity Analysis: Coverage by High-Volatility Definition}
\label{tab:threshold_sensitivity}
\begin{tabular}{lcccc}
\toprule
& \multicolumn{4}{c}{High-Volatility Coverage} \\
\cmidrule(lr){2-5}
Method & $>$50\% & $>$67\% & $>$75\% & $>$90\% \\
\midrule
Vol-Scaled CP & 91.4\% & 91.5\% & 92.0\% & 94.7\% \\
Standard CP & 74.1\% & 66.9\% & 62.8\% & 52.6\% \\
\midrule
Improvement & +17.3pp & +24.6pp & +29.2pp & +42.1pp \\
\midrule
$n$ per factor & $\approx$185 & $\approx$122 & $\approx$92 & $\approx$37 \\
\bottomrule
\end{tabular}
\begin{flushleft}
\small\textit{Note:} Columns show coverage for observations above the indicated volatility percentile (test period 1994--2024). Averages across six factors. Bottom row shows approximate sample size per factor at each threshold.
\end{flushleft}
\end{table}

The results are robust to threshold definition. Volatility-scaled CP maintains 91--95\% coverage regardless of how ``high volatility'' is defined, while standard CP deteriorates sharply at more extreme thresholds (dropping to 53\% for the top decile). This confirms that our findings are not an artifact of the median-split definition.

\subsection{Sensitivity to Volatility Estimation Window}

Our main analysis uses 12-month trailing realized volatility. Table~\ref{tab:window_sensitivity} examines sensitivity to this choice.

\begin{table}[H]
\centering
\caption{Sensitivity Analysis: Coverage by Volatility Estimation Window}
\label{tab:window_sensitivity}
\begin{tabular}{lcccc}
\toprule
& \multicolumn{4}{c}{High-Volatility Coverage (Vol-Scaled CP)} \\
\cmidrule(lr){2-5}
Factor & 6-month & 12-month & 24-month & EWMA$_{\lambda=0.94}$ \\
\midrule
Mkt-RF & 88.5\% & 89.1\% & 87.6\% & 91.4\% \\
SMB & 92.9\% & 93.5\% & 91.8\% & 90.9\% \\
HML & 88.6\% & 89.7\% & 88.0\% & 89.3\% \\
RMW & 84.8\% & 85.9\% & 84.2\% & 88.8\% \\
CMA & 90.2\% & 91.8\% & 89.4\% & 85.0\% \\
Mom & 90.8\% & 91.3\% & 89.1\% & 89.8\% \\
\midrule
\textbf{Average} & \textbf{89.3\%} & \textbf{90.2\%} & \textbf{88.4\%} & \textbf{89.2\%} \\
\bottomrule
\end{tabular}
\begin{flushleft}
\small\textit{Note:} EWMA uses RiskMetrics decay parameter $\lambda = 0.94$. All windows achieve near-target coverage, with 12-month slightly outperforming alternatives.
\end{flushleft}
\end{table}

The results are robust across estimation windows: all variants achieve 88--90\% high-volatility coverage, substantially outperforming standard CP (74\%). The 12-month window performs marginally better than alternatives, likely reflecting a bias-variance tradeoff:
\begin{itemize}
    \item \textbf{Shorter windows (6-month, EWMA):} More responsive to recent volatility changes but noisier estimates.
    \item \textbf{Longer windows (24-month):} More stable estimates but slower to adapt to regime changes.
\end{itemize}
The 12-month window balances these considerations, though practitioners should choose based on their specific application. For high-frequency trading, EWMA's faster adaptation may be preferable; for strategic asset allocation, longer windows may suffice.

\subsection{Sensitivity to Time Period}

A key concern is whether results are driven by specific historical episodes. Table~\ref{tab:era_sensitivity} shows performance across different eras.

\begin{table}[H]
\centering
\caption{Subperiod Sensitivity: High-Volatility Coverage Across Eras}
\label{tab:era_sensitivity}
\begin{tabular}{lccc}
\toprule
Period & Standard CP & Vol-Scaled CP & Improvement \\
\midrule
Full Sample (1963--2024) & 74.1\% & 91.4\% & $+$17.3pp \\
1963--1985 & 85.1\% & 87.6\% & $+$2.5pp \\
1986--2000 & 71.1\% & 90.7\% & $+$19.6pp \\
2001--2010 & 86.7\% & 99.4\% & $+$12.8pp \\
2011--2024 & 65.9\% & 85.3\% & $+$19.4pp \\
\bottomrule
\end{tabular}
\begin{flushleft}
\small\textit{Note:} High-volatility coverage averaged across six factors. Each subperiod uses within-period 50/50 calibration/test split.
\end{flushleft}
\end{table}

Key findings:
\begin{enumerate}
    \item \textbf{Vol-Scaled CP consistently outperforms.} Across all eras, volatility-scaled CP achieves higher coverage than standard CP. The improvement ranges from 2.5pp (1963--1985) to 19.6pp (1986--2000).

    \item \textbf{Largest gains in volatile eras.} The 1986--2000 period (including Black Monday 1987, Asian Crisis 1997, LTCM 1998) and 2011--2024 period (COVID crash 2020) show the largest improvements. These are precisely the periods where volatility scaling matters most.

    \item \textbf{Smallest gains in stable eras.} The 1963--1985 period shows only 2.5pp improvement. With less volatility variation, the benefit of volatility scaling is smaller---but it never hurts.

    \item \textbf{2011--2024 shows room for improvement.} Vol-Scaled CP achieves only 85.3\% in the most recent era. We investigate this underperformance in Section~\ref{sec:diagnostic_2011}.
\end{enumerate}

\subsection{Diagnostic Analysis: Why Does 2011--2024 Underperform?}
\label{sec:diagnostic_2011}

The 4.7 percentage point shortfall in the 2011--2024 period (85.3\% vs 90\% target) warrants investigation. We identify four contributing factors:

\textbf{1. COVID-19 crash (March 2020).} The market factor dropped $-13.4\%$ in March 2020, a 3+ sigma event relative to historical volatility. Twelve-month trailing realized volatility, by construction, cannot anticipate such sudden spikes. We estimate this single month accounts for approximately 1--2 percentage points of the coverage shortfall. Excluding February--April 2020, high-volatility coverage improves to approximately 87\%.

\textbf{2. Lower volatility dispersion.} Post-2011 markets exhibit more compressed volatility regimes, likely due to central bank intervention (quantitative easing, forward guidance). The ratio of high-volatility to low-volatility periods averages approximately 1.7$\times$ in 2011--2024 versus 2.2$\times$ in 1986--2000. With smaller volatility dispersion, the benefit from volatility scaling is mechanically reduced---there is less heteroskedasticity to correct.

\textbf{3. Shorter high-volatility regimes.} Post-GFC high-volatility episodes are briefer, with V-shaped recoveries (COVID crash recovered within months). The 12-month trailing window is too slow to adapt to such short spikes. This suggests that for modern market conditions, shorter volatility estimation windows (6-month) or EWMA may be preferable. Indeed, Table~\ref{tab:window_sensitivity} shows the 6-month window achieves 89.3\% average coverage versus 88.4\% for the 24-month window.

\textbf{4. Structural market changes.} Factor dynamics in the post-2011 period differ from earlier eras due to the growth of passive investing (ETFs), algorithmic trading, and fundamentally different monetary policy regimes. These structural shifts may require domain-specific adaptations beyond simple volatility scaling.

\textbf{Practical implications.} For practitioners operating in post-2011 market conditions:
\begin{enumerate}
    \item Consider shorter volatility estimation windows (6-month or EWMA with $\lambda = 0.94$) for faster adaptation to regime changes.
    \item Accept that extreme tail events (COVID, GFC) may cause unavoidable temporary under-coverage---no method can fully anticipate 3+ sigma surprises.
    \item Consider reporting coverage separately for ``normal'' and ``crisis'' periods to provide users with realistic expectations.
\end{enumerate}

This analysis demonstrates that the 2011--2024 underperformance is not a fundamental failure of volatility-scaled conformal prediction, but rather reflects the inherent challenge of adapting to shorter, more extreme volatility spikes in modern markets.

\subsection{Validity of the I.I.D.\ Assumption}
\label{sec:iid_main}

Our theoretical results (Theorems~\ref{thm:undercover}--\ref{thm:robust}) require that standardized residuals $\epsilon_t = (Y_t - \mu)/\sigma_t$ are i.i.d. We test this assumption using Ljung-Box tests for autocorrelation (in levels and squares) and runs tests for independence. Table~\ref{tab:iid_main} reports the results.

\begin{table}[H]
\centering
\caption{Tests of I.I.D.\ Assumption on Standardized Residuals}
\label{tab:iid_main}
\begin{tabular}{lccc}
\toprule
Factor & Autocorr.\ (LB) & ARCH Effects (LB$^2$) & Independence (Runs) \\
\midrule
Mkt-RF & Pass ($p=0.93$) & Pass ($p=0.26$) & Pass ($p=0.85$) \\
SMB & \textbf{Fail} ($p<0.001$) & \textbf{Fail} ($p<0.001$) & \textbf{Fail} ($p=0.002$) \\
HML & \textbf{Fail} ($p<0.001$) & \textbf{Fail} ($p=0.001$) & \textbf{Fail} ($p<0.001$) \\
RMW & \textbf{Fail} ($p<0.001$) & \textbf{Fail} ($p=0.002$) & \textbf{Fail} ($p=0.005$) \\
CMA & \textbf{Fail} ($p<0.001$) & Pass ($p=0.10$) & \textbf{Fail} ($p=0.009$) \\
Mom & Pass ($p=0.61$) & \textbf{Fail} ($p<0.001$) & Pass ($p=0.36$) \\
\bottomrule
\end{tabular}
\begin{flushleft}
\small\textit{Note:} Ljung-Box tests at lag 12. Bold indicates rejection at 5\% level. Only Mkt-RF passes all three tests; Mom passes two of three.
\end{flushleft}
\end{table}

\textbf{Implications.} The i.i.d.\ assumption is well-supported for Mkt-RF (passes all three tests) and partially supported for Momentum (passes autocorrelation and runs tests, but fails the ARCH effects test at $p<0.001$). SMB, HML, RMW, and CMA fail multiple tests. This has important consequences for interpreting our results:

\begin{enumerate}
    \item \textbf{Factors with strong theoretical support (Mkt-RF):} Our coverage theorems formally apply. Mkt-RF passes all three i.i.d.\ tests and achieves 89.1\% high-volatility coverage, matching theory.

    \item \textbf{Factors with partial theoretical support (Momentum):} Momentum passes 2 of 3 tests (autocorrelation and runs), but fails the ARCH effects test, indicating some residual volatility clustering. Despite this, it achieves 91.3\% coverage---our theoretical results may apply approximately under weak dependence.

    \item \textbf{Factors without formal guarantees (SMB, HML, RMW, CMA):} Our theoretical results should be interpreted as \textit{heuristic guidance} rather than formal guarantees. The empirical success (86--97\% high-volatility coverage) suggests robustness beyond the i.i.d.\ setting, but we cannot claim finite-sample validity.
\end{enumerate}

\textbf{Why does volatility scaling still work?} We offer three explanations: (i) the autocorrelation in standardized residuals, while statistically significant, is economically modest (first-order autocorrelations of 0.05--0.15); (ii) volatility scaling removes the dominant source of non-exchangeability, leaving only second-order effects; and (iii) the finite-sample correction in conformal prediction provides some buffer against mild violations. The strong out-of-sample performance (Section~\ref{sec:oos}) provides confidence that the method works in practice, even where theory is incomplete.

\subsection{Limitations}

We acknowledge several limitations:

\begin{enumerate}
    \item \textbf{I.I.D.\ assumption fails for most factors.} As documented in Section~\ref{sec:iid_main}, our theoretical guarantees formally apply only to Mkt-RF and Momentum. For the other four factors, our results are empirically validated but lack theoretical coverage guarantees. This is the most significant limitation of our analysis.

    \item \textbf{Multiplicative heteroskedasticity assumption.} Our theoretical guarantees require the location-scale model (Assumption~\ref{ass:het}). While this nests many common volatility models, it rules out certain forms of heteroskedasticity (e.g., leverage effects where negative returns have different volatility impact than positive returns).

    \item \textbf{Monthly data only.} Results may differ at daily or intraday frequencies where microstructure effects, bid-ask bounce, and non-synchronous trading become important.

    \item \textbf{Factor returns only.} Individual stocks or portfolios may exhibit different volatility dynamics. Factor returns are aggregated across many securities, which may smooth idiosyncratic effects.

    \item \textbf{Volatility estimation error.} Realized volatility is a proxy for true conditional volatility. Our robustness bounds (Theorem~\ref{thm:robust}) quantify but do not eliminate this error. In practice, the bounds are conservative---empirical performance is substantially better than worst-case theory suggests.
\end{enumerate}

%------------------------------------------------------------------
\section{Conclusion}
\label{sec:conclusion}
%------------------------------------------------------------------

We document that standard conformal prediction under-covers factor returns during high-volatility periods, achieving only 74\% coverage versus the 90\% target. Volatility-scaled conformal prediction---a technique dating to \citet{papadopoulos2008normalized}---restores coverage to the target level. Our contribution is the first systematic analysis of this phenomenon for financial applications.

\textbf{Empirical findings.} Volatility-scaled CP achieves 91.6\% high-volatility coverage, compared to 74.3\% for standard CP. With fair comparison (monthly refitting, Student-t innovations), GARCH achieves 89.6\%---close to volatility-scaled CP but requiring substantially more complexity. CQR, despite being designed for heteroskedastic data, fails to improve over standard CP (74.1\%), and our diagnostic analysis explains why: it cannot extrapolate to volatility regimes not seen during calibration.

\textbf{Theoretical analysis and its limits.} We adapt existing conformal prediction theory to the multiplicative heteroskedasticity setting common in finance. Our bounds (Theorems~\ref{thm:undercover}--\ref{thm:robust}) are not methodologically novel but provide explicit, interpretable guidance for practitioners. \textbf{A critical caveat:} Our theoretical guarantees require i.i.d.\ standardized residuals (Assumption~\ref{ass:het}), which formal testing confirms holds fully for only 1 of 6 factors (Mkt-RF passes all three tests) and partially for Momentum (passes 2 of 3 tests, failing only the ARCH effects test). For the remaining four factors (SMB, HML, RMW, CMA), our results are \textit{empirically validated} but lack formal finite-sample coverage guarantees. The strong out-of-sample performance (90.2\% high-volatility coverage) suggests the method is robust to mild assumption violations, but practitioners should interpret coverage claims for these factors as empirical observations rather than theoretical guarantees.

\textbf{Practical recommendations.} For practitioners, volatility-scaled CP offers an attractive tradeoff: near-optimal coverage with minimal complexity. The implementation requires one line of code, no distributional assumptions, and no refitting. GARCH can match this performance with sufficient care, but requires choosing model order, innovation distribution, and refitting frequency---each introducing potential for error.

\textbf{Limitations and future work.} Our analysis is limited to monthly factor returns; results may differ at higher frequencies. The i.i.d.\ assumption fails for most factors, limiting theoretical guarantees. The 2011--2024 period shows weaker performance (85.3\% coverage), suggesting room for improvement in modern market conditions. Extending these methods to individual stocks, portfolios, and alternative asset classes remains for future work.

%------------------------------------------------------------------
% Data Availability
%------------------------------------------------------------------

\section*{Data Availability Statement}

The Fama-French factor data used in this study are publicly available from the Kenneth French Data Library (\url{https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html}). Replication code is available from the author upon request.

%------------------------------------------------------------------
% References
%------------------------------------------------------------------

\bibliographystyle{apalike}
\bibliography{references}

%------------------------------------------------------------------
% Appendix
%------------------------------------------------------------------

\appendix

\section{Implementation Details}
\label{app:implementation}

\subsection{Volatility Signal}

We compute trailing 12-month realized volatility normalized by expanding median:

\begin{verbatim}
rolling_vol = returns.rolling(12).std()
median_vol = rolling_vol.expanding().median()
signal = rolling_vol / median_vol
\end{verbatim}

\subsection{Volatility-Scaled Conformal Prediction}

\begin{verbatim}
# Standardized nonconformity scores
scores = np.abs(y_cal - pred_cal) / vol_cal

# Quantile with finite-sample correction
n = len(scores)
q_level = min(np.ceil((n + 1) * (1 - alpha)) / n, 1.0)
q = np.quantile(scores, q_level)

# Prediction interval scaled by test volatility
lower = pred_test - q * vol_test
upper = pred_test + q * vol_test
\end{verbatim}

\section{Data Description}
\label{app:data}

\begin{table}[H]
\centering
\caption{Factor Return Summary Statistics (Monthly, 1963--2024)}
\label{tab:data_summary}
\begin{tabular}{lcccccc}
\toprule
Factor & Mean & Std & Min & Max & Sharpe & Obs \\
\midrule
Mkt-RF & 0.60\% & 4.46\% & -23.2\% & 16.1\% & 0.46 & 738 \\
SMB & 0.18\% & 3.03\% & -15.5\% & 18.5\% & 0.20 & 738 \\
HML & 0.28\% & 2.97\% & -13.8\% & 12.9\% & 0.33 & 738 \\
RMW & 0.26\% & 2.22\% & -19.0\% & 13.1\% & 0.41 & 738 \\
CMA & 0.24\% & 2.07\% & -7.1\% & 9.0\% & 0.40 & 738 \\
Mom & 0.60\% & 4.18\% & -34.3\% & 18.0\% & 0.50 & 738 \\
\bottomrule
\end{tabular}
\end{table}

Data source: Kenneth French Data Library.

\section{Statistical Tests}
\label{app:stats}

Coverage estimates are proportions with standard error $\text{SE} = \sqrt{p(1-p)/n}$. With approximately 185 observations per volatility regime, SE $\approx$ 2--3 percentage points.

We use two-proportion z-tests to assess significance of coverage differences:
\begin{equation}
    z = \frac{p_1 - p_2}{\sqrt{\bar{p}(1-\bar{p})(1/n_1 + 1/n_2)}}
\end{equation}

where $\bar{p}$ is the pooled proportion.

The improvement from standard CP (74.2\%) to volatility scaling (90.2\%) is 16 percentage points with $z > 4$ and $p < 0.001$, highly significant.

\section{Validation of the I.I.D. Assumption}
\label{app:iid}

Our theoretical results (Theorems~\ref{thm:undercover}--\ref{thm:robust}) require that standardized residuals $\epsilon_t = (Y_t - \mu)/\sigma_t$ are i.i.d.\ (Assumption~\ref{ass:het}). We test this assumption using three diagnostic tests:

\begin{enumerate}
    \item \textbf{Ljung-Box test (LB):} Tests for autocorrelation in $\hat{\epsilon}_t$ at lag 12.
    \item \textbf{Ljung-Box on squares (LB$^2$):} Tests for remaining ARCH effects in $\hat{\epsilon}_t^2$.
    \item \textbf{Runs test:} Tests whether the sign sequence is random (independence).
\end{enumerate}

\begin{table}[H]
\centering
\caption{Tests of I.I.D. Assumption on Standardized Residuals}
\label{tab:iid_tests}
\begin{tabular}{lcccccc}
\toprule
& \multicolumn{2}{c}{Autocorrelation} & \multicolumn{2}{c}{ARCH Effects} & \multicolumn{2}{c}{Independence} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
Factor & LB(12) & $p$-value & LB$^2$(12) & $p$-value & Runs $z$ & $p$-value \\
\midrule
Mkt-RF & 5.7 & 0.930 & 14.7 & 0.256 & 0.18 & 0.854 \\
SMB & 61.3 & \textbf{0.000} & 69.0 & \textbf{0.000} & $-$3.06 & \textbf{0.002} \\
HML & 41.2 & \textbf{0.000} & 32.9 & \textbf{0.001} & $-$4.31 & \textbf{0.000} \\
RMW & 38.3 & \textbf{0.000} & 30.3 & \textbf{0.002} & $-$2.84 & \textbf{0.005} \\
CMA & 38.1 & \textbf{0.000} & 18.4 & 0.103 & $-$2.62 & \textbf{0.009} \\
Mom & 10.1 & 0.608 & 41.4 & \textbf{0.000} & $-$0.92 & 0.357 \\
\midrule
Reject at 5\% & \multicolumn{2}{c}{4/6} & \multicolumn{2}{c}{4/6} & \multicolumn{2}{c}{4/6} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Results.} The i.i.d.\ assumption is well-supported for Mkt-RF (the market factor), which passes all three tests. Momentum passes the autocorrelation and runs tests but fails the ARCH effects test ($p<0.001$), indicating residual volatility clustering. SMB, HML, RMW, and CMA fail multiple tests, showing significant autocorrelation and/or remaining ARCH effects in standardized residuals.

\textbf{Interpretation.} The violation of the i.i.d.\ assumption for 4 of 6 factors means our theoretical guarantees (Theorems~\ref{thm:uniform}--\ref{thm:robust}) do not formally apply to these factors. We therefore distinguish between:

\begin{enumerate}
    \item \textbf{Factors with strong theoretical support (Mkt-RF):} Mkt-RF passes all three i.i.d.\ tests. For this factor, our coverage guarantees formally hold, and empirical results (89.1\% high-vol coverage) match theory.

    \item \textbf{Factors with partial theoretical support (Momentum):} Momentum passes 2 of 3 tests but fails ARCH effects ($p<0.001$), indicating residual volatility clustering. The 91.3\% coverage suggests our results apply approximately under weak dependence.

    \item \textbf{Factors without formal guarantees (SMB, HML, RMW, CMA):} These factors fail multiple i.i.d.\ tests. Our theoretical results should be interpreted as \textit{heuristic guidance} rather than formal guarantees. The method still achieves 86--97\% high-volatility coverage empirically, but we cannot claim finite-sample validity.
\end{enumerate}

\textbf{Why does volatility scaling still work?} We offer three explanations:

\begin{enumerate}
    \item \textbf{Weak dependence:} The autocorrelation in standardized residuals, while statistically significant, is economically modest (first-order autocorrelations range from 0.05 to 0.15). Under weak mixing conditions \citep{yu1994rates}, conformal prediction retains approximate validity.

    \item \textbf{Volatility as dominant effect:} Volatility scaling removes the primary source of non-exchangeability. Residual autocorrelation is a second-order effect that causes smaller coverage distortions than the 16pp gap from ignoring volatility.

    \item \textbf{Conservative calibration:} The finite-sample correction $\lceil(n+1)(1-\alpha)\rceil/(n+1)$ provides some buffer against mild assumption violations.
\end{enumerate}

\textbf{Recommendation.} For factors that reject the i.i.d.\ assumption, practitioners should interpret our coverage results as empirically validated rather than theoretically guaranteed. The strong out-of-sample performance (Section~\ref{sec:oos}) provides confidence that the method works in practice, even where theory is incomplete.

\section{Proofs}
\label{app:proofs}

\subsection{Proof of Theorem~\ref{thm:robust} (Robustness)}

\begin{proof}
With estimated volatilities, the nonconformity scores become:
\begin{equation}
    \hat{s}_i = \frac{|Y_i - \mu|}{\hat{\sigma}_i} = |\epsilon_i| \cdot \frac{\sigma_i}{\hat{\sigma}_i}
\end{equation}

Under Assumption~\ref{ass:error} (bounded relative error $\delta$):
\begin{equation}
    \frac{\sigma_i}{\hat{\sigma}_i} \in \left[\frac{1}{1+\delta}, \frac{1}{1-\delta}\right]
\end{equation}

For small $\delta$, this is approximately $[1-\delta, 1+\delta] + O(\delta^2)$.

Let $\hat{q}_{\text{vs}}$ be the $(1-\alpha)$-quantile of $\{\hat{s}_i\}_{i=1}^n$, and $q_\alpha = F_{|\epsilon|}^{-1}(1-\alpha)$ be the true quantile. By the Dvoretzky-Kiefer-Wolfowitz inequality and Lipschitz properties of quantiles:
\begin{equation}
    |\hat{q}_{\text{vs}} - q_\alpha| \leq \delta \cdot q_\alpha + O(1/\sqrt{n}) + O(\delta^2)
\end{equation}

The coverage probability for the test point:
\begin{align}
    \mathbb{P}(Y_{n+1} \in \hat{\mathcal{C}}_{\text{vs}})
    &= \mathbb{P}\left(\frac{|Y_{n+1} - \mu|}{\hat{\sigma}_{n+1}} \leq \hat{q}_{\text{vs}}\right) \\
    &= \mathbb{P}\left(|\epsilon_{n+1}| \cdot \frac{\sigma_{n+1}}{\hat{\sigma}_{n+1}} \leq \hat{q}_{\text{vs}}\right)
\end{align}

In the worst case (maximum estimation error in both directions):
\begin{align}
    \mathbb{P}(Y_{n+1} \in \hat{\mathcal{C}}_{\text{vs}})
    &\geq \mathbb{P}\left(|\epsilon_{n+1}| \cdot (1+\delta) \leq q_\alpha(1-\delta)\right) \\
    &= \mathbb{P}\left(|\epsilon_{n+1}| \leq \frac{q_\alpha(1-\delta)}{1+\delta}\right) \\
    &\approx \mathbb{P}\left(|\epsilon_{n+1}| \leq q_\alpha(1-2\delta)\right) + O(\delta^2)
\end{align}

By Taylor expansion of $F_{|\epsilon|}$ around $q_\alpha$:
\begin{align}
    F_{|\epsilon|}(q_\alpha - 2\delta q_\alpha)
    &= F_{|\epsilon|}(q_\alpha) - 2\delta q_\alpha \cdot f_{|\epsilon|}(q_\alpha) + O(\delta^2) \\
    &= (1-\alpha) - 2\delta \cdot f_{|\epsilon|}(q_\alpha) \cdot q_\alpha + O(\delta^2)
\end{align}

This completes the proof.
\end{proof}

\subsection{Proof of Corollary (Coverage Loss Bound)}

For Gaussian innovations $\epsilon \sim N(0,1)$, we have $|\epsilon|$ following a half-normal distribution.

At $\alpha = 0.1$: $q_{0.1} = \Phi^{-1}(0.95) \approx 1.645$, where $\Phi$ is the standard normal CDF.

The density of the half-normal at $q_{0.1}$:
\begin{equation}
    f_{|\epsilon|}(q_{0.1}) = \sqrt{\frac{2}{\pi}} \exp\left(-\frac{q_{0.1}^2}{2}\right) \approx \sqrt{\frac{2}{\pi}} \cdot 0.259 \approx 0.207
\end{equation}

Therefore:
\begin{equation}
    2 \cdot f_{|\epsilon|}(q_\alpha) \cdot q_\alpha \approx 2 \times 0.207 \times 1.645 \approx 0.68
\end{equation}

The first-order coverage loss is bounded by $0.68\delta$. For $\delta = 0.1$ (10\% relative error), this gives approximately 7 percentage points of coverage loss. In practice, the bound may be somewhat looser due to:
\begin{itemize}
    \item Higher-order terms in the Taylor expansion ($O(\delta^2)$)
    \item Finite-sample effects in quantile estimation
    \item Correlated estimation errors across calibration and test points
\end{itemize}

\subsection{Extension to Unknown Mean}

When the mean $\mu$ is estimated by $\hat{\mu} = \bar{Y}_{\text{cal}}$, we have:
\begin{equation}
    |\hat{\mu} - \mu| = O_p(1/\sqrt{n})
\end{equation}

The nonconformity scores become:
\begin{equation}
    s_i = \frac{|Y_i - \hat{\mu}|}{\sigma_i} = |\epsilon_i + (\mu - \hat{\mu})/\sigma_i|
\end{equation}

For large $n$, the perturbation $(\mu - \hat{\mu})/\sigma_i = O_p(1/\sqrt{n})$ is negligible. The proofs of Theorems~\ref{thm:uniform} and~\ref{thm:robust} go through with an additional $O(1/\sqrt{n})$ error term.

\end{document}
